{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python standard library imports\n",
    "import datetime as dt\n",
    "import pathlib\n",
    "import re\n",
    "#Scientific Python ecosystem imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Text mining packages\n",
    "import nltk as nltk\n",
    "from whoosh.lang.porter import stem\n",
    "#MM Import\n",
    "import datetime as dt\n",
    "import pathlib\n",
    "import logging\n",
    "import copy\n",
    "import unicodedata\n",
    "\n",
    "from docx2python import docx2python\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "import urllib.request\n",
    "\n",
    "#from polmap.polmap import preprocess_text, doc2text # replaced the keyword processing block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_keywords(a_string, stop_words, exception_dict=None):\n",
    "    \"\"\"\n",
    "    Prepare text for mapping.\n",
    "    \"\"\"\n",
    "    text_string = a_string\n",
    "\n",
    "    if text_string==None: #this should be moved to the prepare keywords wrapper function\n",
    "        return None\n",
    "    # if text_string is not str:\n",
    "    #     raise TypeError('text_string is not a string') \n",
    "    #     #How to return the name of the variable passed by user with format?\n",
    "    # Get error when using it with apply and lambda in pandas\n",
    "    \n",
    "    if exception_dict==None:\n",
    "        exception_dict = {\"aids\": \"ai&ds&\",\n",
    "                          \"productivity\": \"pro&ductivity&\",\n",
    "                          \"remittances\" : \"remit&tance&\"                 \n",
    "                          }\n",
    "    elif exception_dict is not dict:\n",
    "        raise TypeError('exception_dict is not a dict')\n",
    "    \n",
    "    reverse_exception_dict = {value : key for key, value in exception_dict.items()}\n",
    "\n",
    "    #stem_fun = lambda rgx_str: stem(rgx_str) if rgx_str not in rgx_str else rgx_str\n",
    "        \n",
    "    #remove all from stop_words to keep in keywords.\n",
    "    # Review scoping rules in python, this fails with:\n",
    "    # NameError: name 'stop_words' is not defined when called in lambda function\n",
    "    # I would expect the variable to always exist whenever calling the function, but it does not.\n",
    "    #if stop_words==None:\n",
    "    #    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    #    stop_words.remove(\"all\")\n",
    "\n",
    "       \n",
    "    #text_string = text_string.replace('\\xa0',' ') #Remove some weird \\xa0 characters\n",
    "\n",
    "    text_string = text_string.lower().strip()\n",
    "    \n",
    "    text_string = re.sub(r'[^a-zA-Z- ]+', '', text_string)\n",
    "    \n",
    "    text_string = re.sub(r'([\\w-]+)', r' \\1 ', text_string) #Equivalent to center, adds leading and trailing space to the captured group\n",
    "    \n",
    "    text_string = text_string.replace(' rd ', ' R&D ')\n",
    "    \n",
    "    text_string = re.sub(r'([\\w-]{3,}|ph)', r'\\1', text_string)\n",
    "    \n",
    "    # not sure this is working the way intended, \n",
    "    # if the plan was to drop two characters words,\n",
    "    # it is not  as we are however counting also spaces.\n",
    "    # an easy fix would be to move it before the centering of the terms\n",
    "    \n",
    "    for key, value in exception_dict.items(): #Protect exceptions from stemming\n",
    "        text_string = text_string.replace(key, value)\n",
    "    \n",
    "    for word in stop_words: #Remove stopwords\n",
    "        text_string = text_string.replace(' '+word+' ', '') \n",
    "    \n",
    "    text_string = re.sub(r'[a-zA-Z-&]+', \n",
    "    lambda rgx_word: ' '+stem(rgx_word.group())+' ',# if not rgx_word in stop_words else rgx_word, \n",
    "    text_string) #if not rgx_word in stop_words if rgx_word != \"aids\",\n",
    "        \n",
    "    for key, value in exception_dict.items(): #Restore words from exception protection\n",
    "        text_string = text_string.replace(value, key)\n",
    "    \n",
    "    text_string = ' '+text_string+' '\n",
    "    \n",
    "    text_string = re.sub(r' {2,}', r' ', text_string) #Remove multiple spaces\n",
    "        \n",
    "    return text_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text_string, stop_words, exception_dict=None):\n",
    "    \"\"\"\n",
    "    Prepare text for mapping.\n",
    "    \"\"\"\n",
    "    \n",
    "    # if text_string is not str:\n",
    "    #     raise TypeError('text_string is not a string') \n",
    "    #     #How to return the name of the variable passed by user with format?\n",
    "    # Get error when using it with apply and lambda in pandas\n",
    "    \n",
    "    if exception_dict==None:\n",
    "        exception_dict = {\"aids\": \"ai&ds&\",\n",
    "                          \"productivity\": \"pro&ductivity&\",\n",
    "                          \"remittances\" : \"remit&tance&\"                 \n",
    "                          }\n",
    "    elif exception_dict is not dict:\n",
    "        raise TypeError('exception_dict is not a dict')\n",
    "    \n",
    "    reverse_exception_dict={value : key for key, value in exception_dict.items()}\n",
    "    \n",
    "    #remove all from stop_words to keep in keywords.\n",
    "    # Review scoping rules in python, this fails with:\n",
    "    # NameError: name 'stop_words' is not defined when called in lambda function\n",
    "    # I would expect the variable to always exist whenever calling the function, but it does not.\n",
    "    #if stop_words==None:\n",
    "    #    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    #    stop_words.remove(\"all\")\n",
    " \n",
    "\n",
    "    text_string = text_string.split(\";\")\n",
    "    \n",
    "    text_list = map(lambda term: term.split(),  text_string)    \n",
    "    \n",
    "    text_list = [ [term.lower().strip() for term in terms]\n",
    "                      for terms in text_list ]    \n",
    "\n",
    "    text_list = [ [re.sub(r\"[^a-zA-Z- ]+\", '', term) for term in terms]\n",
    "                      for terms in text_list ]    \n",
    "\n",
    "    text_list = [ [term.center(len(term)+2) for term in terms]\n",
    "                      for terms in text_list ]    \n",
    "\n",
    "    text_list = [ [term.replace(\" rd \", \"R&D\") for term in terms]\n",
    "                      for terms in text_list ]    \n",
    "\n",
    "    text_list = [ [term for term in terms if len(term) > 2 or term == \"ph\" ]\n",
    "                      for terms in text_list ]\n",
    "    \n",
    "    # not sure this is working the way intended, \n",
    "    # if the plan was to drop two characters words,\n",
    "    # it is not  as we are however counting also spaces.\n",
    "    # an easy fix would be to move it before the centering of the terms\n",
    "    text_list = [ [term.strip(' ') for term in terms]\n",
    "                      for terms in text_list ]    \n",
    "    \n",
    "    text_list = [ [exception_dict[term] if term in exception_dict.keys() \n",
    "                      else term\n",
    "                      for term in terms]\n",
    "                      for terms in text_list ]    \n",
    "    \n",
    "    text_list = [ [ stem(term) for term in terms \n",
    "                      if not term in stop_words if term != \"aids\" ]\n",
    "                      for terms in text_list ]    \n",
    "    \n",
    "    text_list = [ [reverse_exception_dict[term] if term in reverse_exception_dict.keys() \n",
    "                      else term\n",
    "                      for term in terms]\n",
    "                      for terms in text_list ]    \n",
    "        \n",
    "    text_list = [ ' '.join(terms) for terms in text_list ]    \n",
    "\n",
    "    text_list = [ ' '+terms+' ' for terms in text_list ]    \n",
    "    \n",
    "    text_list = [terms for terms in text_list if terms!='  ']\n",
    "    \n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "########### 2) MM Read the list of keywords and apply the prepare_keyords text processing function from polmap\n",
    "\n",
    "keys = pd.read_excel('keys_update_27012020.xlsx', sheet_name = 'Target_keys' ) #MM 'keys_from_RAKE-GBV_DB_SB_v3.xlsx', sheet_name= 'Sheet1'\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stop_words.remove(\"all\")\n",
    "\n",
    "raw_keywords_df=keys['Keys'].str.split(';', expand=True)\n",
    "\n",
    "keys['Keys']=keys['Keys'].apply(lambda x: preprocess_text(x, stop_words))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = keys['Keys'].apply(pd.Series)\n",
    "\n",
    "keywords.replace(to_replace={'':None, np.NaN:None}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_keywords_df.replace(to_replace={'':None, np.NaN:None}, inplace=True)\n",
    "raw_keywords_df.drop(labels=57, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_keywords_df=raw_keywords_df.applymap(lambda x: prepare_keywords(x, stop_words))\n",
    "processed_keywords_df.replace(to_replace={'':None, np.NaN:None}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vs_standard=processed_keywords_df.compare(keywords, keep_shape=True)\n",
    "raw_vs_new = raw_keywords_df.compare(processed_keywords_df, keep_shape=True)\n",
    "raw_vs_standard = raw_keywords_df.compare(keywords, keep_shape=True)\n",
    "#comparison[1][1]='=IF(AND(ISBLANK(New_preprocessing!B2),ISBLANK(Standard_processing!B2)),\"\",IF(New_preprocessing!C2=Standard_preprocessing!C2,TRUE,FALSE))'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_keywords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_keywords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('updated_processed_keywords_test.xlsx', engine='xlsxwriter') as writer:\n",
    "    raw_keywords_df.to_excel(writer, sheet_name='Raw_keywords')\n",
    "    processed_keywords_df.to_excel(writer, sheet_name='New_preprocessing')\n",
    "    keywords.to_excel(writer, sheet_name='Standard_preprocessing')\n",
    "    new_vs_standard.to_excel(writer, sheet_name='New_vs_Standard')\n",
    "    raw_vs_new.to_excel(writer, sheet_name='Raw_vs_New')\n",
    "    raw_vs_standard.to_excel(writer, sheet_name='Raw_vs_Standard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('polmap': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3c701ea15ff6b8cd345d7eda6702a5a5acbef34c5d809ba6ada83c604f672a97"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}