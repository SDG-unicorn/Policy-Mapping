{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, pathlib, logging, time, argparse\n",
    "import datetime as dt\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from whoosh.lang.porter import stem\n",
    "from itertools import chain\n",
    "\n",
    "##MM imports\n",
    "from polmap.polmap import make_directories, preprocess_text, doc2text, SDGrefs_mapper # replaced the keyword processing block\n",
    "\n",
    "#import fromRtoPython\n",
    "\n",
    "from docx2python import docx2python\n",
    " \n",
    "from polmap.polmap import make_directories, preprocess_text, doc2text # replaced the keyword processing block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "usage: ipykernel_launcher [-h] [-i INPUT] [-o OUTPUT] [-k KEYWORDS]\nipykernel_launcher: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9028 --control=9026 --hb=9025 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"09fdeb6d-8b55-4899-b93f-1c65612cca72\" --shell=9027 --transport=\"tcp\" --iopub=9029 --f=/tmp/tmp-59NY33z0VfANm3.json\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "2",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"\"\"Keyword counting program.\n",
    "Given a set of keywords, and a set of pdf, docx and html documents in a directory, it counts in each documents how many times a certain keyword is found.\n",
    "The results are provided for both the whole run and for each documents, together with the raw and stemmed text of the documents and keywords.\"\"\")\n",
    "parser.add_argument('-i', '--input', help='Input directory')\n",
    "parser.add_argument('-o', '--output', help='Output directory')\n",
    "parser.add_argument('-k', '--keywords', help='Keywords file')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEI_mapping = pathlib.Path.cwd() / 'output' / 'SA_and_Kenya_TEI_2021-02-18_T114717' / 'results' / 'mapping_SA_and_Kenya_TEI_2021-02-18_T114717.xlsx'\n",
    "\n",
    "targets = pd.read_excel(TEI_mapping, index_col=0, sheet_name= 'Target_raw_count')\n",
    "goals = pd.read_excel(TEI_mapping, index_col=0, sheet_name= 'Goal_raw_count')\n",
    "targets['Goal'] = targets['Target'].apply(lambda x: str('SDG '+x.split('.')[0]))\n",
    "targets.drop(labels='Target', axis=1, inplace=True)\n",
    "targets = targets[['Policy', 'Goal', 'Keyword', 'Count', 'Textlength']]\n",
    "total = pd.concat([targets, goals])\n",
    "total = total.groupby(['Policy','Goal']).sum()\n",
    "\n",
    "total.to_csv('TEI_by_goal.csv')\n",
    "total.to_json('TEI_by_goal.json')\n",
    "\n",
    "total.head(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#E5243B\",\"#DDA63A\",\"#4C9F38\",\"#C5192D\",\n",
    "\"#FF3A21\",\"#26BDE2\",\"#FCC30B\",\"#A21942\",\n",
    "\"#FD6925\",\"#DD1367\",\"#FD9D24\",\"#BF8B2E\",\n",
    "\"#3F7E44\",\"#0A97D9\",\"#56C02B\",\"#00689D\",\"#19486A\"]\n",
    "\n",
    "sdg_colors = {f'SDG {count}' : color for count, color in enumerate(colors)}\n",
    "\n",
    "bubble_chart = BubbleChart(area=total['Goal'],\n",
    "                           bubble_spacing=0.1)\n",
    "\n",
    "bubble_chart.collapse()\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw=dict(aspect=\"equal\"))\n",
    "bubble_chart.plot(\n",
    "    ax, browser_market_share['Goal'], sdg_colors[browser_market_share['Goal']])\n",
    "ax.axis(\"off\")\n",
    "ax.relim()\n",
    "ax.autoscale_view()\n",
    "ax.set_title('Browser market share')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text(dest_folder, filename, text_string):\n",
    "\n",
    "    #dest folder must be an existing path\n",
    "    \n",
    "    filename_parent = filename.parent\n",
    "\n",
    "    doctext_name = dest_folder.joinpath(filename_parent) \n",
    "    doctext_name.mkdir(mode=0o777, parents=True, exist_ok=True)\n",
    "    doctext_name = doctext_name / str(filename.name.replace('.','_')+'.txt')\n",
    "\n",
    "    with open(doctext_name, 'w', encoding='utf-8') as file_:\n",
    "            file_.write(text_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_documents['Doc_text']=policy_documents['Input_files'].apply(doc2text)\n",
    "#policy_documents.apply(lambda col: save_text(doctext_dir, col['Paths'], col['Doc_text']))\n",
    "\n",
    "for filename, text in zip(policy_documents['Paths'], policy_documents['Doc_text']):\n",
    "    save_text(doctext_dir, filename, text)\n",
    "\n",
    "# # PDFtext = []\n",
    "# # counter = 0\n",
    "# for doc_path in files:\n",
    "#     counter += 1\n",
    "#     try:\n",
    "#         policy_text=[]\n",
    "#         doc_text = doc2text(doc_path)\n",
    "#         while '\\n\\n\\n\\n' in doc_text : doc_text = doc_text.replace('\\n\\n\\n\\n', '\\n\\n\\n') #docx2python specific fix. would probably fit better elsewhere\n",
    "#         policy_text.append(doc_text)\n",
    "#         doctext_ = doc_path.parts[doc_path.parts.index(input_dir.name)+1:]\n",
    "#         doctext_name =  doctext_dir.joinpath(*doctext_)\n",
    "#         doctext_name.parent.mkdir(mode=0o777, parents=True, exist_ok=True)\n",
    "#         doctext_name = doctext_name.parent.joinpath(doctext_name.name.replace('.','_')+'.txt')\n",
    "#         with open(doctext_name, 'w', encoding='utf-8') as file_:\n",
    "#            file_.write(doc_text)\n",
    "#         PDFtext.append(['/'.join(doctext_),' ; '.join(policy_text)])\n",
    "#     except Exception as excptn: #MM I'd log errors as described in https://realpython.com/python-logging/, we need to test this.\n",
    "#         print(excptn)\n",
    "#         logging.exception('{doc_file} raised exception: {exception} \\n\\n'.format(doc_file=doc_path.name, exception=excptn))\n",
    "\n",
    "\n",
    "# with open(log_file, 'a') as f:\n",
    "#     f.write( \n",
    "#         '3) Reading, converting and saving {docs} documents as text: {seconds:.3e} seconds\\n\\n'.format(docs=len(PDFtext),seconds=(time.time()-start_time))\n",
    "#     )\n",
    "\n",
    "# print('Step 3: Converted {docs} documents to text.\\n'.format(docs=len(PDFtext)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}